\chapter{Marco Teórico}\label{chapter:state-of-the-art}

\section{Fundamentos de los Problemas de Satisfacción de Restricciones y SAT}
\label{sec:fundamentos-sat-csp}

Los Problemas de Satisfacción de Restricciones (CSP, por sus siglas en inglés) constituyen un paradigma esencial para la modelación de problemas combinatorios en inteligencia artificial, investigación operativa y ciencias de la computación. Formalmente, un CSP se define como una tripleta $(V,D,C)$, donde $V$ representa un conjunto de variables, $D$ sus dominios discretos finitos, y $C$ un conjunto de restricciones que determinan las combinaciones válidas de valores \textbf{39}. Por ejemplo, en un problema de asignación de horarios, $V$ corresponde a los cursos, $D$ a los horarios disponibles, y $C$ a las reglas que impiden superposiciones. La solución del problema consiste en una asignación de valores a las variables que satisface todas las restricciones, y en algunos casos, adicionalmente, optimiza ciertos criterios como la utilización de recursos \textbf{40}.

\subsection{SAT como Caso Especial de CSP y su NP-Completitud}
El Problema de Satisfacibilidad Booleana (SAT, por sus siglas en inglés) se considera un caso particular de CSP, en el cual los dominios de las variables son binarios (${0,1}$) y las restricciones se expresan mediante fórmulas en Forma Normal Conjuntiva (FNC) \textbf{43}. Una fórmula en FNC se compone de una conjunción de cláusulas, donde cada cláusula es una disyunción de literales, es decir, variables o sus negaciones \textbf{6}. Resolver un problema SAT implica determinar si existe una asignación de valores que satisfaga simultáneamente todas las cláusulas, lo cual equivale a resolver un CSP binario con restricciones específicas.

La importancia teórica de SAT se fundamenta en su clasificación como problema NP-completo, establecida por Cook y Levin en 1971 \textbf{2,24}. Esta clasificación conlleva dos implicaciones fundamentales: en primer lugar, cualquier problema perteneciente a la clase NP puede reducirse a una instancia de SAT en tiempo polinomial \textbf{26}; en segundo lugar, la existencia de un algoritmo de tiempo polinomial que resuelva SAT implicaría que $P=NP$, lo cual provocaría un colapso en la jerarquía de complejidad computacional \textbf{2}. Si bien en la práctica los solucionadores (solvers) actuales logran resolver instancias que contienen millones de variables \textbf{3}, en el peor de los casos SAT presenta una complejidad exponencial intrínseca \textbf{27}.


\subsection{Ineficiencias Fundamentales de SAT}
\label{subsec:ineficiencia-sat}

El enfoque de fuerza bruta para resolver SAT —consistente en evaluar las $2^n$ asignaciones posibles mediante tablas de verdad— evidencia su carácter intratable en el peor de los casos \textbf{19}. Esta explosión combinatoria se intensifica en fórmulas que carecen de estructura discernible, en las cuales técnicas como la propagación unitaria o el aprendizaje de cláusulas presentan un impacto limitado \textbf{30}. En particular, las instancias aleatorias del problema 3-SAT próximas al umbral de fase (aproximadamente 4.26 cláusulas por variable \textbf{30}) provocan que algoritmos clásicos como DPLL experimenten un crecimiento exponencial en el tiempo de ejecución \textbf{27}.

No obstante, SAT se consolida como una herramienta práctica debido a dos factores principales: (1) la posibilidad de codificar CSPs genéricos en FNC mediante técnicas como codificaciones directas o el método de Tseitin \textbf{44}; y (2) la existencia de solucionadores modernos basados en CDCL, los cuales aprovechan regularidades empíricas observadas en instancias industriales \textbf{3}. Esta dualidad entre complejidad teórica y eficiencia práctica posiciona a SAT como un componente central en aplicaciones como verificación de hardware, planificación autónoma y criptoanálisis \textbf{39}.

\subsection{Relación Práctica entre CSPs y SAT}
\label{subsec:csp-sat-relacion}

Si bien los CSPs permiten modelar problemas con dominios arbitrarios y restricciones globales —lo cual representa una ventaja frente a la rigidez booleana de SAT—, su resolución directa mediante técnicas como \textit{backtracking} o la aplicación de consistencia de arco presenta limitaciones similares en cuanto a escalabilidad \textbf{46}. Como respuesta a estas limitaciones, se recurre frecuentemente a la traducción de CSPs a SAT, con el objetivo de aprovechar las décadas de avances en la optimización de solucionadores CDCL \textbf{44}. Estudios empíricos muestran que ciertas codificaciones eficientes —por ejemplo, el \textit{order encoding} para restricciones de orden— pueden reducir hasta en un 60\% el tiempo de resolución en comparación con enfoques nativos basados en CSPs \textbf{45}.

Sin embargo, dicha traducción conlleva compromisos. Mientras SAT se adapta mejor a restricciones locales y cláusulas pequeñas, los CSPs ofrecen mecanismos más adecuados para el tratamiento de restricciones globales —como la restricción \textit{alldifferent}— mediante propagadores especializados \textbf{46}. En contextos como la asignación de turnos hospitalarios, los modelos CSP con restricciones de recursos logran resolver instancias en minutos, mientras que sus equivalentes codificados en SAT pueden requerir varias horas debido a la proliferación de cláusulas \textbf{46}. Esta dicotomía resalta la necesidad de seleccionar el paradigma de resolución en función de la estructura del problema.

Cada enfoque posee un nicho de aplicabilidad particular. Por ejemplo, la Programación con Restricciones (CP) resulta más efectiva en tareas de planificación con restricciones complejas; la Programación Lineal Entera Mixta (MILP) es preferida en problemas de optimización logística con restricciones lineales; y SAT destaca en verificación formal, donde la traducción a FNC se realiza de manera natural \textbf{39,40}. La elección del paradigma adecuado depende fundamentalmente de la capacidad para explotar la estructura subyacente del problema, lo cual explica el éxito práctico de SAT a pesar de su complejidad teórica \textbf{3}.

%\begin{figure}[h]
%\centering
%\includegraphics[width=0.85\textwidth]{sat-csp-comparison.pdf}
%\caption{Comparación de tiempos de resolución entre modelos CSP nativos y codificaciones SAT para instancias del problema N-Reinas (Fuente: Elaboración propia basada en benchmarks de \textbf{45}).}
%\label{fig:sat-csp-comp}
%\end{figure}

Esta sección establece las bases para el análisis detallado de la evolución de los \textit{solvers} SAT (Sección \ref{sec:evolucion-sat-solvers}), donde se examina cómo técnicas como CDCL superan las ineficiencias teóricas mediante innovaciones algorítmicas pragmáticas.

\section{Evolución de los SAT \textit{solvers}: Principio de Resolución, DP, DPLL y CDCL}
\label{sec:evolucion-sat-solvers}

La evolución de los solucionadores SAT constituye un hito en la ciencia computacional, pues convierte un problema teóricamente intratable en una herramienta práctica de amplio uso industrial. Este desarrollo se apoya en tres pilares algorítmicos: el Principio de Resolución, los métodos Davis–Putnam (DP) y Davis–Putnam–Logemann–Loveland (DPLL), y la revolución moderna impulsada por los solucionadores de aprendizaje de cláusulas dirigido por conflictos (CDCL). Este recorrido refleja no solo avances técnicos, sino también una comprensión profunda de cómo combinar teoría y pragmatismo para superar las barreras de complejidad inherentes al problema de la satisfacibilidad booleana (SAT)\footnote{Problema NP-completo que determina si existe una asignación de valores verdaderos y falsos que satisfaga una fórmula lógica dada.}.

\subsection{Principio de Resolución: Fundamento Teórico}
El Principio de Resolución (PR), propuesto originalmente en el contexto de la lógica proposicional, constituye la base teórica de numerosos algoritmos SAT. Este principio permite derivar nuevas cláusulas a partir de pares de cláusulas que contienen literales complementarios, reduciendo progresivamente la fórmula hasta detectar una contradicción o verificar su satisfacibilidad. Aunque es completo para fórmulas en Forma Normal Conjuntiva (FNC), su aplicación directa resulta impráctica debido al crecimiento exponencial en el número de cláusulas generadas \textbf{12}. Sin embargo, su relevancia conceptual fundamenta y guía el diseño de métodos más eficientes.

\subsection{Algoritmo Davis–Putnam (DP): Primer Intento Práctico}
El algoritmo Davis–Putnam (DP) propone una aplicación sistemática del Principio de Resolución en un entorno computacional \textbf{5}. Su estrategia se basa en dos operaciones principales: (1) la eliminación de literales puros, que asigna valores a variables que aparecen con un único signo en todas las cláusulas; y (2) la resolución dirigida, que elimina variables seleccionadas mediante la generación de cláusulas resolventes.  

Aunque DP evita la exploración exhaustiva de las $2^n$ asignaciones, su dependencia de la resolución genera un crecimiento exponencial en el número de cláusulas intermedias, lo que limita su eficacia a instancias de tamaño reducido \textbf{12}.

\subsection{Algoritmo DPLL: Búsqueda Inteligente con Retroceso}
El algoritmo DPLL refina DP sustituyendo la resolución explícita por una búsqueda con retroceso en el espacio de asignaciones \textbf{12}. Incorpora tres mecanismos fundamentales:
\begin{itemize}
  \item \textbf{Propagación unitaria}: asigna valores a literales en cláusulas unitarias, simplificando la fórmula antes de cada decisión.
  \item \textbf{Eliminación de literales puros}: mantiene la optimización heredada de DP para reducir el tamaño de la fórmula.
  \item \textbf{Bifurcación con retroceso}: selecciona heurísticamente valores para variables no asignadas y retrocede al detectar conflictos.
\end{itemize}

Este método explora en profundidad el árbol de decisiones y reduce el uso de memoria respecto a DP. Sin embargo, su eficiencia disminuye en instancias industriales debido a la repetición de exploraciones conflictivas y a la falta de mecanismos que aprovechen información de conflictos previos \textbf{8}.

\subsection{CDCL: Solucionadores de Aprendizaje de Cláusulas Dirigido por Conflictos}
El enfoque CDCL introduce dos innovaciones clave sobre DPLL: el aprendizaje de cláusulas y el retroceso no cronológico \textbf{12}.  

El aprendizaje de cláusulas analiza los conflictos para generar cláusulas que evitan la repetición de subárboles conflictivos. El retroceso no cronológico permite regresar a niveles de decisión relevantes sin deshacer todos los pasos intermedios.  

Estos mecanismos reducen la exploración redundante de subespacios, mejoran la adaptabilidad heurística durante la búsqueda y superan la ineficiencia del retroceso cronológico de DPLL \textbf{6,17}.


\subsection{Algoritmo Davis–Putnam (DP): Primer Intento Práctico}
El algoritmo Davis–Putnam (DP) propone una aplicación sistemática del Principio de Resolución en un entorno computacional \textbf{5}. Su estrategia se basa en dos operaciones principales: (1) la eliminación de literales puros, que asigna valores a variables que aparecen con un único signo en todas las cláusulas; y (2) la resolución dirigida, que elimina variables seleccionadas mediante la generación de cláusulas resolventes.  

Aunque DP evita la exploración exhaustiva de las $2^n$ asignaciones, su dependencia de la resolución genera un crecimiento exponencial en el número de cláusulas intermedias, lo que limita su eficacia a instancias de tamaño reducido \textbf{12}.

\subsection{Algoritmo DPLL: Búsqueda Inteligente con Retroceso}
El algoritmo DPLL refina DP sustituyendo la resolución explícita por una búsqueda con retroceso en el espacio de asignaciones \textbf{12}. Incorpora tres mecanismos fundamentales:
\begin{itemize}
  \item \textbf{Propagación unitaria}: asigna valores a literales en cláusulas unitarias, simplificando la fórmula antes de cada decisión.
  \item \textbf{Eliminación de literales puros}: mantiene la optimización heredada de DP para reducir el tamaño de la fórmula.
  \item \textbf{Bifurcación con retroceso}: selecciona heurísticamente valores para variables no asignadas y retrocede al detectar conflictos.
\end{itemize}

Este método explora en profundidad el árbol de decisiones y reduce el uso de memoria respecto a DP. Sin embargo, su eficiencia disminuye en instancias industriales debido a la repetición de exploraciones conflictivas y a la falta de mecanismos que aprovechen información de conflictos previos \textbf{8}.

\subsection{CDCL: Solucionadores de Aprendizaje de Cláusulas Dirigido por Conflictos}
El enfoque CDCL introduce dos innovaciones clave sobre DPLL: el aprendizaje de cláusulas y el retroceso no cronológico \textbf{12}.  

El aprendizaje de cláusulas analiza los conflictos para generar cláusulas que evitan la repetición de subárboles conflictivos. El retroceso no cronológico permite regresar a niveles de decisión relevantes sin deshacer todos los pasos intermedios.  

Estos mecanismos reducen la exploración redundante de subespacios, mejoran la adaptabilidad heurística durante la búsqueda y superan la ineficiencia del retroceso cronológico de DPLL \textbf{6,17}.

\subsubsection{Otras Contribuciones Relevantes}
\label{subsubsec:otras-mejoras}

El ecosistema de optimizaciones para CDCL incorpora varias líneas de mejora. En primer lugar, la gestión de cláusulas aprendidas emplea métricas como la LBD para identificar y eliminar cláusulas redundantes, al tiempo que conserva aquellas con alto valor predictivo (denominadas \textit{glue clauses}) \textbf{14–17}. A continuación, la combinación con búsqueda local, mediante técnicas de \textit{re-phasing} basadas en frecuencias de conflicto, incrementa el rendimiento en instancias satisfacibles en hasta un 40 % \textbf{1}. Finalmente, ciertas meta-heurísticas, como AutoSAT, investigan el uso de modelos de lenguaje grande para ajustar dinámicamente los parámetros del solver; esta línea de trabajo muestra potencial, aunque su adopción en entornos prácticos permanece limitada \textbf{35}.

%\begin{figure}[h]
%\centering
%\includegraphics[width=0.8\textwidth]{cdcl-evolucion.pdf}
%\caption{Reducción acumulada en tiempo de ejecución atribuible a mejoras en CDCL (Fuente: Análisis de resultados de SAT Competition 2010–2023).}
%\label{fig:cdcl-evol}
%\end{figure}

\subsection{CDCL como Motor para Problemas con Restricciones}
\label{subsec:cdcl-csp}

La aplicación de CDCL a problemas de satisfacción de restricciones (CSP) se apoya en su arquitectura adaptable. Por un lado, la heurística VSIDS detecta patrones emergentes en la codificación de restricciones, favoreciendo variables con alta incidencia en conflictos \textbf{15,21}. Por otro lado, las políticas de reinicio basadas en LBD permiten gestionar la modularidad de los subproblemas generados por la traducción a FNC. Asimismo, técnicas como CFUP priorizan cláusulas centrales que reflejan jerarquías implícitas en la red de restricciones \textbf{96}.  

No obstante, la traducción de restricciones globales a cláusulas booleanas puede provocar un aumento significativo en el número de cláusulas, lo que penaliza el rendimiento en problemas con propagadores especializados de alto nivel \textbf{46}.

\subsection{Conclusión: De la Teoría a la Aplicación Práctica}
La evolución desde el Principio de Resolución y DP hasta los solucionadores CDCL demuestra que la integración de mecanismos de inferencia e información de conflictos permite abordar problemas NP-completos con eficiencia razonable en la práctica. DPLL sienta las bases de la búsqueda con retroceso, mientras que CDCL introduce el aprendizaje reflexivo y el retroceso no cronológico para reducir exploraciones redundantes \textbf{5,7,11}. Estas innovaciones, junto con mejoras en heurísticas y estructuras de datos, establecen a los solucionadores SAT como herramientas esenciales en verificación, planificación y análisis automático de restricciones.

\section{Solucionadores actuales}

\subsection{CaDiCaL}
CaDiCaL es un solver SAT moderno implementado en C++ que combina claridad de diseño y eficiencia práctica. La arquitectura se organiza en un módulo interno, responsable de la búsqueda CDCL y de técnicas de simplificación de fórmulas —como eliminación acotada de variables (BVE), vivificación e instanciación—; y en un módulo externo que actúa como fachada, gestiona la API y, en modo incremental, revierte pasos de \textit{inprocessing} para mantener limpia la pila de reconstrucción.

El solver se ofrece tanto como biblioteca en C++ y C, como aplicación independiente, y permite la integración de \textit{propagadores de usuario} para sustituir motores basados en MiniSat. También incluye mecanismos de inversión de eliminación de cláusulas y soporte para SAT incremental. %%Hasta aqui cita del documento Cadical_2%%%%%%%%%%%%%%%%%%%%%%%

Las decisiones de ramificación se guían por heurísticas de actividad basadas en VSIDS, alternando entre fases estables y enfocadas para mejorar el rendimiento en instancias satisfacibles. Además, se incorpora la noción de \textit{Literal Stability}, que prioriza aquellos literales que permanecen satisfechos durante periodos prolongados. %Combining VSIDS and CHB using restart in SAT.pdf  
%Unit Propagation with Stable Watches.pdf

Los reinicios dinámicos permiten al solver escapar de subespacios improductivos sin perder las cláusulas aprendidas. Para ello, CaDiCaL emplea políticas adaptativas que utilizan contadores de eventos —por ejemplo, accesos a memoria— en lugar de mediciones temporales directas, lo que garantiza determinismo entre ejecuciones. Estas políticas alternan modos estable y enfocado, y bloquean reinicios cuando la búsqueda se encuentra próxima a una solución potencial, siguiendo estrategias propuestas en la literatura. %Combining VSIDS and CHB Using Restarts in SAT.pdf  
%Evaluating CDCL Restart Schemes.pdf  
%Revisiting Restarts of CDCL Should the Search Information be Preserved.pdf

Aunque estas técnicas mejoran notablemente el rendimiento, la complejidad de las políticas adaptativas y la sensibilidad de sus parámetros pueden introducir sobrecarga computacional y requerir ajustes cuidadosos para evitar reinicios excesivos o insuficientes.
 
Las fuentes no especifican directamente que DLIS (Dynamic Largest Individual Sum) sea una heurística de decisión implementada por defecto en CaDiCaL. Sin embargo, se indica que CaDiCaL y su reimplementación Kissat emplean la heurística VSIDS (Variable State Independent Decaying Sum). En Kissat, el solver alterna entre modos estable y enfocado; VSIDS se aplica en las fases estables, dirigidas principalmente a instancias satisfacibles. %Combining VSIDS and CHB using restart in SAT

Aunque no se documenta la inclusión de DLIS en CaDiCaL, puede inferirse que este solver moderno se basa en esquemas de actividad de variables como VSIDS, dada su prevalencia y extensa bibliografía. %Cadical 2.0, Combining VSIDS and CHB Using Restart...

Además, la selección de literales en CaDiCaL puede incorporar el concepto de Literal Stability, que prioriza aquellos literales que permanecen satisfechos durante intervalos prolongados al determinar los watched literals. %Unit Propagation with Stable Watches.pdf

\subsection{Políticas de reinicio}
Los reinicios constituyen un mecanismo esencial en los solvers CDCL, pues facilitan la salida de regiones improductivas sin descartar las cláusulas aprendidas. %Combining VSIDS and CHB Using Restarts in SAT.pdf, Revisiting Restarts of CDCL Should the Search Information be Preserved.pdf

CaDiCaL implementa políticas de reinicio dinámicas que se ajustan al comportamiento interno del solver. %Evaluating CDCL Restart Schemes.pdf, Revisiting Restarts of CDCL Should the Search Information be Preserved.pdf
Por ejemplo, Kissat alterna entre modos estable y enfocado, determinando la duración de cada fase mediante el recuento de accesos a memoria en lugar de medidas temporales, lo que garantiza determinismo entre ejecuciones. %Combining VSIDS and CHB Using Restarts in SAT.pdf, Better Decision Heuristics in CDCL through Local Search and Target Phases.pdf
En el modo orientado a instancias satisfacibles, Kissat utiliza permanentemente la estrategia de target phasing. %Better Decision Heuristics in CDCL through Local Search and Target Phases.pdf

Las políticas de rephasing de CaDiCaL y Kissat se inspiran en Glucose y alternan entre distintos modos de fase ("B" para best phasing, "W" para walk, "O" para original, "I" para inverted y "\#" para random). %Better Decision Heuristics in CDCL through Local Search and Target Phases.pdf

Todas las restart policies pueden ajustarse mediante múltiples parámetros para adaptarse a las características de cada instancia. %Misma fuente que la anterior


% tOOOda esta vaina de la Modularidad y Extensibilidad del codigo tiene referencia a Cadical 2.0
\subsection{Modularidad y Extensibilidad del Código de CaDiCaL}
La modularidad y la extensibilidad constituyen objetivos esenciales en el diseño de CaDiCaL \cite{Cadical2.0}. Este solver se ha convertido en plantilla para el "hack track" de la competencia SAT desde 2021, evidenciando su facilidad de adaptación. Los mecanismos principales para modificar su comportamiento incluyen:
\begin{itemize}
  \item \textbf{API rica}: proporciona una interfaz en C++ (y limitada en C) que permite extender funcionalidades y personalizar la interacción con el solver.
  \item \textbf{Propagadores de usuario (ExternalPropagator)}: habilita la implementación de propagadores externos capaces de importar y exportar cláusulas aprendidas o sugerir decisiones al solver, otorgando control directo sobre la búsqueda.
  \item \textbf{Estructura del código fuente}: el código, organizado de forma clara y modular, facilita su uso como modelo para portar e integrar técnicas de última generación en otros solvers.
\end{itemize}
Diversas investigaciones han extendido CaDiCaL para incorporar nuevas características, algunas de las cuales se han integrado en la versión oficial.

\subsection{Ventajas de CaDiCaL para Experimentación}
CaDiCaL resulta adecuado para estudios académicos sobre heurísticas y políticas de reinicio en SAT solving por las siguientes razones:
\begin{itemize}
  \item \textbf{Diseño limpio y modular}: la arquitectura está orientada a la comprensibilidad y facilidad de modificación, lo que simplifica la implementación de nuevas estrategias sin la complejidad de otros solvers avanzados.
  \item \textbf{Flexibilidad en heurísticas y reinicios}: aunque dispone de configuraciones predeterminadas, permite alternar entre modos estable y enfocado, y ajustar esquemas de rephasing para probar variaciones en políticas de reinicio \cite{BetterDecisionHeuristics}.
  \item \textbf{Rendimiento competitivo}: mantiene un desempeño de última generación, garantizando que los resultados experimentales sean representativos del estado del arte.
  \item \textbf{Adopción en la comunidad}: su uso extendido en investigación genera un entorno colaborativo y recursos para investigadores.
  \item \textbf{Documentación exhaustiva}: el código fuente cuenta con comentarios detallados, facilitando la comprensión y manipulación del solver por parte de nuevos usuarios.
\end{itemize}
% Exceptuando el que esta indicado en esta seccion, todas las referencias son a Cadical 2.0


\subsection{Comparación con Otros Solvers}

MiniSAT representa un solver CDCL clásico que implementa propagación unitaria, heurística de actividad y retrocesos cronológicos. No obstante, carece de optimizaciones avanzadas, como gestión adaptativa de cláusulas aprendidas, políticas de reinicio dinámicas y una API extensible, lo cual limita su desempeño frente a solvers más recientes %Conflict-Driven Clause Learning SAT Solvers Marquwa-Silva Handbook of Satisfiability 2021.pdf, Improving SAT Solvers by Exploiting Empirical Characteristics of CDCL.pdf, Cadical 2.0.

En contraste, Glucose incorpora la métrica LBD (Literal Block Distance) para evaluar la relevancia de las cláusulas aprendidas y optimizar la eliminación de las de menor impacto. Asimismo, emplea políticas de reinicio basadas en LBD que favorecen la resolución en escenarios incrementales. Sin embargo, su conjunto de características y el grado de modularidad de su código son inferiores al de CaDiCaL, lo que dificulta su adaptación en contextos de investigación %Machine Learning for SAT Solvers.pdf, Marquwa-Silva Handbook of Satisfiability 2021.pdf, Evaluating CDCL Restart Schemes.pdf, Cadical 2.0.

Por último, Kissat constituye una reimplementación optimizada de CaDiCaL en lenguaje C que combina heurísticas de actividad y reinicios adaptativos para maximizar la velocidad y reducir el uso de memoria. En consecuencia, lidera competiciones SAT recientes gracias a su equilibrio entre rendimiento y eficiencia de recursos. No obstante, su API es menos completa y carece de soporte integral para técnicas incrementales, lo cual restringe su versatilidad como plataforma de experimentación. En comparación, CaDiCaL mantiene una arquitectura modular que facilita la integración de nuevas técnicas y su utilización como referente en el desarrollo de solvers %Combining VSIDS and CHB Using Restarts in SAT.pdf, Cadical 2.0.


\section{Parámetros de Evaluación para Solvers CDCL: Taxonomía de 	extit{Benchmarks}}
\label{sec:tipos-problemas}
La evaluación sistemática de solvers CDCL exige una taxonomía clara de instancias SAT que permita comparar heurísticas de actividad, estrategias de reinicio y métodos de propagación unitaria. Para este propósito, las instancias se clasifican según su origen y propiedades estructurales, de modo que cada categoría revele puntos fuertes y limitaciones algorítmicas 	extbf{15,17}.

En primer lugar, las 	extit{instancias de aplicación} proceden de problemas industriales, como la verificación de circuitos o la planificación logística. Estas fórmulas presentan estructuras modulares y 	extit{backdoors} pequeños —subconjuntos de variables cuya asignación simplifica significativamente la búsqueda—, lo que permite a heurísticas dinámicas como VSIDS explotar patrones locales mediante el registro de conflictos recientes 	extbf{20,21,23}.

A continuación, las 	extit{instancias combinatorias dificultosas}, diseñadas para desafiar la generalidad de los solvers (por ejemplo, codificaciones del principio del palomar), carecen de la estructura implícita de los casos reales y exhiben simetrías y dependencias globales que ponen a prueba la adaptabilidad de las heurísticas 	extbf{16,19}.

Además, las 	extit{instancias aleatorias}, generadas según modelos Random $k$-SAT, muestran una distribución uniforme de cláusulas sin sesgos estructurales. En estas condiciones, técnicas como el aprendizaje de cláusulas ofrecen beneficios limitados, lo que resulta clave para evaluar el rendimiento en entornos carentes de regularidades 	extbf{17,21}.

Por último, las 	extit{instancias ágiles} surgen de la transformación de problemas de lógica de orden superior a SAT mediante 	extit{bit-blasting}. Estas fórmulas presentan alta densidad de cláusulas y literales auxiliares, lo que prueba la capacidad del solver para manejar estructuras complejas y voluminosas 	extbf{19}.


\subsection{Clasificación por Satisfacibilidad y Propiedades Estructurales}
La distinción entre instancias SAT e UNSAT determina la orientación de las estrategias de resolución. En las primeras, las heurísticas que exploran asignaciones prometedoras —como VSIDS con preservación de fase\textit{ (phase saving)}— potencian la localización rápida de soluciones. Por su parte, las instancias UNSAT requieren la generación de cláusulas aprendidas de alto impacto, con el fin de acotar el espacio de búsqueda y acelerar la refutación \textbf{41}.

Del mismo modo, las propiedades estructurales aportan criterios de evaluación adicionales. La modularidad de la fórmula y la existencia de \textit{backbones} —variables que mantienen el mismo valor en todas las soluciones— facilitan la identificación de subespacios críticos. De igual modo, un \textit{treewidth} reducido correlaciona con una mayor eficiencia de la propagación unitaria, lo que contribuye a disminuir los tiempos de resolución \textbf{20,22}.

\subsection{Densidad y Transición de Fase}
La densidad de una instancia, definida como el cociente entre cláusulas y variables, condiciona su nivel de dificultad. En los modelos aleatorios de 3-SAT, la complejidad alcanza su punto máximo alrededor de 4.27 cláusulas por variable, conocido como umbral de transición de fase \textbf{25}. En esta zona, heurísticas estáticas como DLIS pierden eficacia ante la ausencia de patrones explotables \textbf{17}. En cambio, la combinación de VSIDS con políticas de reinicio basadas en LBD equilibra la exploración global y la explotación local, permitiendo al solver superar con eficiencia estas regiones críticas \textbf{21}.

\subsection{Clasificación por Satisfacibilidad y Propiedades Estructurales}
La distinción entre instancias SAT e UNSAT determina la orientación de las estrategias de resolución. En las primeras, las heurísticas que exploran asignaciones prometedoras —como VSIDS con preservación de fase \textit{(phase saving)}— potencian la localización rápida de soluciones. Por su parte, las instancias UNSAT requieren la generación de cláusulas aprendidas de alto impacto, con el fin de acotar el espacio de búsqueda y acelerar la refutación \textbf{41}.

Del mismo modo, las propiedades estructurales aportan criterios de evaluación adicionales. La modularidad de la fórmula y la existencia de \textit{backbones} —variables que mantienen el mismo valor en todas las soluciones— facilitan la identificación de subespacios críticos. Asimismo, un \textit{treewidth} reducido correlaciona con una mayor eficiencia de la propagación unitaria, lo que contribuye a disminuir los tiempos de resolución \textbf{20,22}.

En instancias estructuradas, sin embargo, densidades elevadas no siempre implican mayor dificultad. Codificaciones compactas de problemas como el coloreado de grafos se resuelven con eficiencia cuando los solvers identifican \textit{backdoors} mediante heurísticas sensibles al contexto \textbf{23}.

\subsection{Densidad y Transición de Fase}
La densidad de una instancia, definida como el cociente entre cláusulas y variables, condiciona su nivel de dificultad. En los modelos aleatorios de 3-SAT, la complejidad alcanza su punto máximo alrededor de 4.27 cláusulas por variable, conocido como umbral de transición de fase \textbf{25}. En esta zona, heurísticas estáticas como DLIS pierden eficacia ante la ausencia de patrones explotables \textbf{17}. En cambio, la combinación de VSIDS con políticas de reinicio basadas en LBD equilibra la exploración global y la explotación local, permitiendo al solver superar con eficiencia estas regiones críticas \textbf{21}.

\subsection{Relevancia para la Evaluación de Heurísticas}
La selección de benchmarks resulta crucial al contrastar técnicas como VSIDS y DLIS. Mientras DLIS, basada en conteos estáticos de aparición de literales, ofrece un rendimiento óptimo en instancias aleatorias alejadas del umbral de transición de fase \textbf{18}, VSIDS prevalece en aplicaciones reales gracias a su adaptación dinámica a patrones de conflicto \textbf{30}. Asimismo, en instancias modulares, las estrategias de reinicio basadas en bandits (MAB) demuestran ventajas al preservar cláusulas \textit{glue}, acelerando la exploración del espacio de búsqueda \textbf{37,21}.

Propiedades estructurales como la presencia de \textit{backbones} o un \textit{treewidth} reducido permiten desglosar el impacto de técnicas específicas: por ejemplo, la selección de cláusulas unitarias mediante CFUP reduce hasta un 40\% el tiempo de resolución en instancias con alta proporción de cláusulas centrales ($LBD\le7$), mientras su efecto es marginal en fórmulas sin comunidad definida \textbf{96,21}.

Este marco taxonómico no solo sistematiza la evaluación de solvers, sino que orienta el diseño de heurísticas híbridas. Por ejemplo, la integración de VSIDS con métricas de centralidad de grafos \textbf{22} mejora la cobertura en instancias combinatorias, mientras el acoplamiento con búsqueda local \textbf{1} beneficia a instancias ágiles. De este modo, la elección estratégica de benchmarks establece un puente entre la complejidad teórica de SAT y su aplicabilidad práctica.



% COSAS EXTRAS POR EXPLICAAAAAARRR!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

%///////////////////////BEGIN ASSUMPTIONS//////////////////////////////////
¿Qué son las 'assumptions'?
•
En esencia, las 'assumptions' permiten invocar un SAT solver con un conjunto de valores ya asignados a ciertas variables. Esto es particularmente útil en escenarios donde el solver se utiliza iterativamente.
•
Por ejemplo, si se necesita agregar o eliminar una cláusula ci entre llamadas al solver, se puede añadir a la fórmula como (ci $\lor$ si), donde si es una variable de activación, selección o indicador. Al establecer si = 1, la cláusula ci se ``considera'' en la fórmula, y al establecer si = 0, no se considera.
•
Esta técnica fue propuesta inicialmente en el solver MiniSat. %Chapter 4 Conflict-Driven Clause Learning SAT Solvers Marquwa-Silva Handbook of Satisfiability 2021.pdf

Además de su rol en la resolución incremental, las variables de activación también se emplean para cláusulas temporales. Por ejemplo, para añadir una cláusula temporal c, se introduce una variable de activación a y se añade (c $\lor$ a) a la fórmula, asumiendo ¬a. Para "eliminar" c, simplemente se añade la cláusula unitaria (a).
•
Un aumento en el número de variables de activación puede impactar negativamente el rendimiento del solver, lo que tradicionalmente se ha abordado mediante reinicios periódicos del solver. Sin embargo, algunos enfoques, como GipSAT, permiten la reutilización de una única variable de activación al eliminar proactivamente las cláusulas aprendidas que la contienen después de cada proceso de resolución. %Deeply Optimizing the SAT Solver fir the IC3 Algorithm.pdf
CaDiCaL, en sus versiones recientes, utiliza 'constraints' que pueden simularse con 'activation literals' en versiones anteriores % Documento cadical

¿Por qué se comprueban antes de la heurística de decisión de variables?
Las 'assumptions' se asignan y se propagan antes de que comience la búsqueda efectiva mediante la heurística de decisión de variables. Esto se debe a la forma en que los solvers CDCL (Conflict-Driven Clause Learning) operan: %Chapter 4 Conflict-Driven Clause Learning SAT Solvers Marquwa-Silva Handbook of Satisfiability 2021.pdf

Propagación Unitaria (BCP) Inicial: El algoritmo CDCL inicia con una fase de Propagación Unitaria (BCP, por sus siglas en inglés, Boolean Constraint Propagation). En esta fase, se asignan valores a las variables que son forzadas por las cláusulas unitarias existentes o por las 'assumptions'.
•
Detección de Conflictos Temprana: Si la Propagación Unitaria (BCP) detecta un conflicto al nivel de decisión 0 (es decir, antes de que el solver haya tomado cualquier decisión propia), significa que la fórmula (junto con las 'assumptions' actuales) es insatisfacible. %AutoSAT Automatically Optimize SAT Solvers via Large Language Models.pdf

•
Eficiencia: Esta comprobación temprana es crucial para la eficiencia. Permite que el solver determine la insatisfacibilidad rápidamente, sin necesidad de explorar el espacio de búsqueda haciendo decisiones de ramificación que, en última instancia, llevarían a un conflicto inevitable debido a los supuestos. %%Chapter 4 Conflict-Driven Clause Learning SAT Solvers Marquwa-Silva Handbook of Satisfiability 2021.pdf
Solo si BCP no detecta conflictos y no todas las variables están asignadas, el solver procede a seleccionar una variable para ramificar utilizando la heurística de decisión.%AutoSAT Automatically Optimize SAT Solvers via Large Language Models.pdf

En resumen, las 'assumptions' son como un punto de partida para el solver. Se procesan inicialmente a través de la propagación unitaria para asegurarse de que la configuración inicial (incluyendo estos supuestos) no genere un conflicto inmediato. Esto optimiza el proceso, ya que evita búsquedas infructuosas en partes del espacio que ya se sabe que son inconsistentes con los supuestos dados.

%///////////////////////////////////END ASSUMPTIONS//////////////////////////

%En resumen, la eficiencia de heurísticas como VSIDS se evalúa en solvers CDCL completos utilizando benchmarks de SAT Competition que representan problemas del mundo real (Aplicación), problemas construidos para ser difíciles (Combinatorios) y, en menor medida para CDCL, problemas aleatorios. Los problemas se clasifican por origen, satisfacibilidad y propiedades estructurales como densidad, modularidad y la existencia de "backdoors". La densidad es particularmente relevante en la zona de transición de fase de las instancias aleatorias.
